# -*- coding: utf-8 -*-
"""CX_Support_RAG_Bot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JZ8kOcdZ2XkNQrlta1nMXdnSsBSPbwA7

Goal:
Build a Q&A chatbot using:

Your support tickets dataset

Google Gemini for answering queries

FAISS for fast similarity search

LangChain to connect everything together
"""

#Install Req Libraries

#Other Req Lib to Install
import os
import streamlit as st
import pandas as pd
from langchain_core.documents import Document
from langchain_community.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import RetrievalQA
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings

# 🔐 Load Gemini API key from Streamlit secrets
try:
    GOOGLE_API_KEY = st.secrets["GOOGLE_API_KEY"]
except Exception:
    st.error("❌ Please set GOOGLE_API_KEY in Streamlit Secrets.")
    st.stop()

# 🔁 Load Data
df = pd.read_csv("customer_support_tickets.csv")

# 📄 Convert tickets to documents
real_documents = []
for _, row in df.iterrows():
    text = f"Ticket Subject: {row['Ticket Subject']}\nTicket Description: {row['Ticket Description']}"
    doc = Document(page_content=text, metadata={"ticket_id": row["Ticket ID"]})
    real_documents.append(doc)

# ➕ Add sample FAQs
sample_faqs = [
    {
        "Ticket ID": "FAQ001",
        "Ticket Subject": "How to update shipping address?",
        "Ticket Description": "To update your shipping address, log in to your account, go to Orders > Manage Orders > Edit Shipping Info."
    },
    {
        "Ticket ID": "FAQ002",
        "Ticket Subject": "How to cancel my order?",
        "Ticket Description": "To cancel your order, go to My Orders and click 'Cancel'. Cancellation is only allowed before the item is shipped."
    },
    {
        "Ticket ID": "FAQ003",
        "Ticket Subject": "What is the refund policy?",
        "Ticket Description": "We offer a full refund within 14 days of delivery if the product is returned in original condition."
    }
]
faq_documents = [Document(page_content=f"Ticket Subject: {faq['Ticket Subject']}\nTicket Description: {faq['Ticket Description']}", metadata={"ticket_id": faq["Ticket ID"]}) for faq in sample_faqs]

# 🔗 Combine documents
all_documents = real_documents + faq_documents

# ✂️ Chunking
splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
all_chunks = splitter.split_documents(all_documents)

# 🌐 Init Gemini Embedding + LLM
embedding = GoogleGenerativeAIEmbeddings(
    model="models/embedding-001",
    google_api_key=GOOGLE_API_KEY
)
llm = ChatGoogleGenerativeAI(
    model="gemini-2.0-flash",
    temperature=0.3,
    google_api_key=GOOGLE_API_KEY
)

# 🧠 Vector Store + RetrievalQA
vectorstore = FAISS.from_documents(all_chunks, embedding)
qa_chain = RetrievalQA.from_llm(
    llm=llm,
    retriever=vectorstore.as_retriever(search_type="similarity", k=3),
    return_source_documents=True
)

# 🚀 Streamlit UI
st.title("🤖 Customer Support RAG Chatbot (Gemini + FAISS)")
user_query = st.text_input("Ask a support question:")

if user_query:
    try:
        result = qa_chain({"query": user_query})
        st.markdown("### 💬 Answer")
        st.write(result["result"])

        st.markdown("### 📚 Sources")
        for doc in result["source_documents"]:
            st.write(f"- Ticket ID: {doc.metadata['ticket_id']}")
    except Exception as e:
        st.error(f"❌ Error: {str(e)}")
