# -*- coding: utf-8 -*-
"""CX_Support_RAG_Bot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JZ8kOcdZ2XkNQrlta1nMXdnSsBSPbwA7

Goal:
Build a Q&A chatbot using:

Your support tickets dataset

Google Gemini for answering queries

FAISS for fast similarity search

LangChain to connect everything together
"""

#Install Req Libraries

#Other Req Lib to Install
import os
import pandas as pd
import streamlit as st
import gradio as gr

from langchain.schema import Document
from langchain_community.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import RetrievalQA
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI

# âœ… Load Google API key from Streamlit secrets
GOOGLE_API_KEY = st.secrets["GOOGLE_API_KEY"]

# âœ… Initialize Gemini models
embedding = GoogleGenerativeAIEmbeddings(
    model="models/embedding-001",
    google_api_key=GOOGLE_API_KEY
)

llm = ChatGoogleGenerativeAI(
    model="gemini-1.5-flash",  # use gemini-1.5-flash or gemini-1.5-pro
    temperature=0.3,
    google_api_key=GOOGLE_API_KEY
)

# âœ… Load your support ticket dataset
df = pd.read_csv("customer_support_tickets.csv")

real_documents = []
for _, row in df.iterrows():
    text = f"Ticket Subject: {row['Ticket Subject']}\nTicket Description: {row['Ticket Description']}"
    doc = Document(page_content=text, metadata={"ticket_id": row["Ticket ID"]})
    real_documents.append(doc)

# âœ… Optional: Add some sample FAQs to improve RAG quality
sample_faqs = [
    {
        "Ticket ID": "FAQ001",
        "Ticket Subject": "How to update shipping address?",
        "Ticket Description": "To update your shipping address, log in to your account, go to Orders > Manage Orders > Edit Shipping Info."
    },
    {
        "Ticket ID": "FAQ002",
        "Ticket Subject": "How to cancel my order?",
        "Ticket Description": "To cancel your order, go to My Orders and click 'Cancel'. Cancellation is only allowed before the item is shipped."
    },
    {
        "Ticket ID": "FAQ003",
        "Ticket Subject": "What is the refund policy?",
        "Ticket Description": "We offer a full refund within 14 days of delivery if the product is returned in original condition."
    }
]

faq_documents = []
for faq in sample_faqs:
    text = f"Ticket Subject: {faq['Ticket Subject']}\nTicket Description: {faq['Ticket Description']}"
    doc = Document(page_content=text, metadata={"ticket_id": faq["Ticket ID"]})
    faq_documents.append(doc)

# âœ… Combine real tickets and FAQs
all_documents = real_documents + faq_documents

# âœ… Chunk the documents for better embeddings
splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
all_chunks = splitter.split_documents(all_documents)

# âœ… Filter out empty or too-long chunks (to avoid Gemini embedding failure)
clean_chunks = [
    doc for doc in all_chunks
    if doc.page_content.strip() != "" and len(doc.page_content.strip()) < 1500
]

# âœ… Build the vector store
vectorstore = FAISS.from_documents(clean_chunks, embedding)

# âœ… Create the RAG chain
qa_chain = RetrievalQA.from_llm(
    llm=llm,
    retriever=vectorstore.as_retriever(search_type="similarity", k=3),
    return_source_documents=True
)

# âœ… Define chatbot logic
def chatbot_response(user_input):
    try:
        result = qa_chain({"query": user_input})
        response = result["result"]
        sources = "\n\nðŸ“š Sources:\n" + "\n".join(
            [f"- {doc.metadata['ticket_id']}" for doc in result["source_documents"]]
        )
        return response + sources
    except Exception as e:
        return f"âŒ Error: {str(e)}"

# âœ… Gradio chatbot UI
with gr.Blocks() as demo:
    gr.Markdown("## ðŸ¤– Customer Support RAG Chatbot (Gemini + FAISS)")
    chatbot = gr.Chatbot(type="messages")
    txt = gr.Textbox(placeholder="Ask a support question and press enter...")

    def respond(user_message, history):
    answer = chatbot_response(user_message)
    history = history + [
        {"role": "user", "content": user_message},
        {"role": "assistant", "content": answer}
    ]
    return history, ""
